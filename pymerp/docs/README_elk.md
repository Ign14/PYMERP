# ELK Monitoring - PYMERP

Sistema de monitoreo centralizado usando Elasticsearch, Logstash y Kibana (ELK Stack) para logs estructurados, an√°lisis de errores, performance y m√©tricas de negocio.

## üìã Tabla de Contenidos

- [Arquitectura](#arquitectura)
- [Inicio R√°pido](#inicio-r√°pido)
- [Configuraci√≥n](#configuraci√≥n)
- [Dashboards](#dashboards)
- [Queries √ötiles](#queries-√∫tiles)
- [Troubleshooting](#troubleshooting)
- [Producci√≥n](#producci√≥n)

---

## üèóÔ∏è Arquitectura

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  Spring Boot    ‚îÇ  Logs en formato JSON (LogstashEncoder)
‚îÇ  Application    ‚îÇ  MDC: traceId, userId, companyId, requestUri, method
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ logs/pymerp.log (rotaci√≥n diaria, max 100MB)
         ‚îÇ
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Logstash      ‚îÇ  Pipeline: input ‚Üí filter ‚Üí output
‚îÇ                 ‚îÇ  - Parse JSON logs
‚îÇ                 ‚îÇ  - Enrich with metadata
‚îÇ                 ‚îÇ  - Extract performance metrics
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Elasticsearch   ‚îÇ  Indices: logs-pymerp-YYYY.MM.dd
‚îÇ                 ‚îÇ  Almacenamiento: 30 d√≠as
‚îÇ                 ‚îÇ  B√∫squeda full-text
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
         ‚îÇ
         ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ    Kibana       ‚îÇ  UI: http://localhost:5601
‚îÇ                 ‚îÇ  Dashboards, visualizaciones, alertas
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üöÄ Inicio R√°pido

### 1. Iniciar Stack ELK

```bash
# Desde la ra√≠z del proyecto
docker-compose -f docker-compose.elk.yml up -d
```

**Servicios:**
- **Elasticsearch:** http://localhost:9200
- **Logstash:** http://localhost:9600
- **Kibana:** http://localhost:5601

### 2. Verificar servicios

```bash
# Elasticsearch health
curl http://localhost:9200/_cluster/health

# Logstash stats
curl http://localhost:9600/_node/stats/pipelines

# Kibana status
curl http://localhost:5601/api/status
```

### 3. Iniciar aplicaci√≥n en modo producci√≥n

```bash
cd backend
./gradlew bootRun --args='--spring.profiles.active=prod'
```

Los logs se generar√°n en formato JSON en:
- **Console:** Output JSON a stdout (capturado por Logstash)
- **File:** `backend/logs/pymerp.log` (rotaci√≥n autom√°tica)

### 4. Configurar Kibana

1. Abrir http://localhost:5601
2. Ir a **Management ‚Üí Stack Management ‚Üí Index Patterns**
3. Click "Create index pattern"
4. Index pattern: `logs-pymerp-*`
5. Time field: `@timestamp`
6. Click "Create index pattern"

---

## ‚öôÔ∏è Configuraci√≥n

### Logback (Spring Boot)

**Archivo:** `backend/src/main/resources/logback-spring.xml`

**Profiles:**
- **dev:** Logs legibles en consola (desarrollo local)
- **prod:** Logs JSON + archivo con rotaci√≥n (producci√≥n)

**MDC Fields:**
- `traceId`: UUID √∫nico por request (tracking distribuido)
- `userId`: Usuario autenticado (desde SecurityContext)
- `companyId`: Compa√±√≠a en contexto multitenancy
- `requestUri`: URI del request HTTP
- `method`: M√©todo HTTP (GET, POST, etc.)

**Header X-Trace-ID:**
Cada response incluye header `X-Trace-ID` con el traceId para debugging.

### Logstash Pipeline

**Archivo:** `logstash/pipeline/logstash.conf`

**Input:**
- TCP port 5000 (logs en tiempo real)
- File `/var/log/pymerp/*.log` (logs desde archivos)

**Filter:**
- Parse timestamp ISO8601
- Tag errores (`level:ERROR`)
- Extract performance metrics (`duration_ms`)
- Enrich con tenant info (`companyId`)

**Output:**
- Elasticsearch index: `logs-pymerp-YYYY.MM.dd`
- Console (debugging, comentar en prod)

### Elasticsearch

**Configuraci√≥n:**
- Single node (desarrollo)
- Sin seguridad (`xpack.security.enabled=false`)
- Memoria: 512MB heap

**Producci√≥n:**
- Cluster multi-node
- Habilitar seguridad (TLS + authentication)
- Aumentar heap seg√∫n volumen de logs

### Kibana

**Dashboards incluidos:**
- Error Monitoring (errores por hora, top errores, stack traces)
- Performance (tiempos de respuesta, requests/min, endpoints lentos)
- Authentication (login attempts, failures, success rate)
- Business Metrics (ventas, compras, clientes, actividad por compa√±√≠a)

Ver detalles en: `kibana/dashboards/README.md`

---

## üìä Dashboards

### 1. Error Monitoring

**URL:** http://localhost:5601/app/dashboards

**Visualizaciones:**
- Errores por hora (√∫ltimas 24h)
- Top 10 errores m√°s frecuentes
- Stack traces recientes
- Errores por compa√±√≠a (multitenancy)

### 2. Performance Monitoring

**Visualizaciones:**
- Tiempos de respuesta (percentiles 50, 95, 99)
- Requests por minuto
- Endpoints m√°s lentos (avg, max duration)
- Requests por m√©todo HTTP (GET, POST, etc.)

### 3. Authentication & Security

**Visualizaciones:**
- Login attempts (√∫ltimas 24h)
- Login failures
- Failed attempts by user
- Success rate (gauge)

### 4. Business Metrics

**Visualizaciones:**
- Ventas creadas (√∫ltimas 7 d√≠as)
- Compras creadas (√∫ltimas 7 d√≠as)
- Nuevos clientes registrados (√∫ltimos 30 d√≠as)
- Actividad por compa√±√≠a
- Operaciones por usuario

---

## üîç Queries √ötiles

### Errores √∫ltimas 24h
```
level:ERROR AND @timestamp:[now-24h TO now]
```

### Buscar por usuario
```
userId:"admin@company.com"
```

### Buscar por compa√±√≠a
```
companyId:1
```

### Performance lento (>1s)
```
duration_ms:>1000
```

### Excepciones con stack trace
```
stack_trace:* AND level:ERROR
```

### Requests a endpoint espec√≠fico
```
requestUri:/api/v1/sales*
```

### Logs de autenticaci√≥n fallida
```
requestUri:/api/v1/auth* AND (level:ERROR OR level:WARN)
```

### Actividad de compa√±√≠a en √∫ltimos 7 d√≠as
```
companyId:1 AND @timestamp:[now-7d TO now]
```

### Buscar por traceId (debugging request completo)
```
traceId:"550e8400-e29b-41d4-a716-446655440000"
```

### Logs de un usuario en rango de tiempo
```
userId:"john@example.com" AND @timestamp:[2025-11-01 TO 2025-11-07]
```

---

## üõ†Ô∏è Troubleshooting

### Elasticsearch no arranca

**S√≠ntoma:** Container `pymerp-elasticsearch` en estado `Restarting`

**Soluci√≥n:**
```bash
# Ver logs
docker logs pymerp-elasticsearch

# Verificar permisos del volumen
docker volume inspect pymerp_elasticsearch-data

# Si es problema de permisos (Linux):
sudo chown -R 1000:1000 /path/to/elasticsearch-data/
```

### Logstash no procesa logs

**S√≠ntoma:** Logs no aparecen en Kibana

**Diagn√≥stico:**
```bash
# Verificar pipeline Logstash
curl -X GET "localhost:9600/_node/stats/pipelines"

# Ver logs de Logstash
docker logs pymerp-logstash

# Verificar que existe archivo de logs
ls -lh backend/logs/pymerp.log
```

**Soluci√≥n:**
- Verificar que aplicaci√≥n est√° en profile `prod`
- Verificar que archivo `backend/logs/pymerp.log` existe
- Reiniciar Logstash: `docker restart pymerp-logstash`

### Kibana no conecta con Elasticsearch

**S√≠ntoma:** Kibana muestra "Kibana server is not ready yet"

**Diagn√≥stico:**
```bash
# Verificar health de Elasticsearch
curl http://localhost:9200/_cluster/health

# Ver logs de Kibana
docker logs pymerp-kibana
```

**Soluci√≥n:**
- Esperar a que Elasticsearch termine de iniciar (health check)
- Verificar que containers est√°n en la misma red `elk`
- Reiniciar Kibana: `docker restart pymerp-kibana`

### Logs no tienen campos MDC

**S√≠ntoma:** Logs no muestran `traceId`, `userId`, `companyId`

**Diagn√≥stico:**
- Verificar que `LoggingContextFilter` est√° registrado en `SecurityConfig`
- Verificar profile activo: `prod` (no `dev`)
- Buscar en Kibana: `traceId:*` (debe retornar resultados)

**Soluci√≥n:**
```bash
# Verificar orden de filtros en SecurityConfig
# LoggingContextFilter debe ir ANTES de JwtAuthenticationFilter

# Reiniciar aplicaci√≥n con profile prod
./gradlew bootRun --args='--spring.profiles.active=prod'
```

### Disco lleno por logs

**S√≠ntoma:** Elasticsearch usa mucho espacio

**Diagn√≥stico:**
```bash
# Ver tama√±o de √≠ndices
curl -X GET "localhost:9200/_cat/indices/logs-pymerp-*?v&s=store.size:desc"

# Ver uso de disco
docker system df
```

**Soluci√≥n:**
```bash
# Eliminar √≠ndices antiguos (mayores a 30 d√≠as)
curl -X DELETE "localhost:9200/logs-pymerp-2025.10.*"

# Configurar ILM (Index Lifecycle Management) para auto-delete
# Ver documentaci√≥n: https://www.elastic.co/guide/en/elasticsearch/reference/current/index-lifecycle-management.html
```

### Performance de Elasticsearch degradada

**S√≠ntoma:** B√∫squedas lentas, alta latencia

**Diagn√≥stico:**
```bash
# Ver stats de cluster
curl -X GET "localhost:9200/_cluster/stats?human&pretty"

# Ver hot threads
curl -X GET "localhost:9200/_nodes/hot_threads"
```

**Soluci√≥n:**
- Aumentar heap de Elasticsearch (`ES_JAVA_OPTS=-Xms1g -Xmx1g`)
- Reducir retenci√≥n de logs (eliminar √≠ndices antiguos)
- Considerar cluster multi-node para producci√≥n

---

## üè≠ Producci√≥n

### Checklist de Seguridad

- [ ] Habilitar autenticaci√≥n en Elasticsearch (`xpack.security.enabled=true`)
- [ ] Configurar TLS para comunicaci√≥n cluster
- [ ] Usar contrase√±as seguras (no defaults)
- [ ] Limitar acceso por firewall (puertos 9200, 5601 solo internos)
- [ ] Habilitar audit logging en Elasticsearch
- [ ] Configurar roles y permisos en Kibana

### Escalabilidad

**Elasticsearch Cluster:**
- **Master nodes:** 3 (quorum, alta disponibilidad)
- **Data nodes:** 3+ (distribuci√≥n de shards)
- **Coordinating nodes:** 2+ (balanceo de carga)

**Logstash:**
- **Workers:** Configurar seg√∫n CPU (`pipeline.workers: 4`)
- **Batch size:** Ajustar seg√∫n throughput (`pipeline.batch.size: 125`)
- **Multiple pipelines:** Separar por tipo de log

**Configuraci√≥n recomendada:**
```yaml
# docker-compose.elk.prod.yml
version: '3.8'
services:
  elasticsearch-master-1:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
    environment:
      - node.name=es-master-1
      - cluster.name=pymerp-cluster
      - discovery.seed_hosts=es-master-2,es-master-3
      - cluster.initial_master_nodes=es-master-1,es-master-2,es-master-3
      - node.roles=master
      - xpack.security.enabled=true
      - "ES_JAVA_OPTS=-Xms2g -Xmx2g"
    volumes:
      - es-master-1-data:/usr/share/elasticsearch/data
  
  # ... (m√°s nodos)
```

### Retenci√≥n de Logs

**Estrategia recomendada:**
- **Hot tier (SSD):** √öltimos 7 d√≠as (b√∫squedas r√°pidas)
- **Warm tier (HDD):** 8-30 d√≠as (b√∫squedas ocasionales)
- **Delete:** >30 d√≠as (cumplimiento GDPR/compliance)

**Configurar ILM Policy:**
```bash
curl -X PUT "localhost:9200/_ilm/policy/pymerp-logs-policy" -H 'Content-Type: application/json' -d'
{
  "policy": {
    "phases": {
      "hot": {
        "actions": {
          "rollover": {
            "max_size": "50GB",
            "max_age": "1d"
          }
        }
      },
      "warm": {
        "min_age": "7d",
        "actions": {
          "allocate": {
            "number_of_replicas": 1
          }
        }
      },
      "delete": {
        "min_age": "30d",
        "actions": {
          "delete": {}
        }
      }
    }
  }
}
'
```

### Backup y Restore

**Snapshot repository:**
```bash
# Configurar snapshot repo (S3, NFS, etc.)
curl -X PUT "localhost:9200/_snapshot/pymerp-backups" -H 'Content-Type: application/json' -d'
{
  "type": "fs",
  "settings": {
    "location": "/mnt/backups/elasticsearch"
  }
}
'

# Crear snapshot
curl -X PUT "localhost:9200/_snapshot/pymerp-backups/snapshot-$(date +%Y%m%d)"

# Restore
curl -X POST "localhost:9200/_snapshot/pymerp-backups/snapshot-20251107/_restore"
```

### Monitoreo del Stack ELK

**Herramientas:**
- **Metricbeat:** M√©tricas de Elasticsearch, Logstash, Kibana
- **Filebeat:** Logs de containers ELK
- **APM:** Application Performance Monitoring

**Alertas cr√≠ticas:**
1. Elasticsearch cluster health != green
2. Disco >85% lleno
3. JVM heap >90% usado
4. No logs recibidos en 5 minutos

---

## üìö Referencias

- [Elasticsearch Documentation](https://www.elastic.co/guide/en/elasticsearch/reference/current/index.html)
- [Logstash Documentation](https://www.elastic.co/guide/en/logstash/current/index.html)
- [Kibana Documentation](https://www.elastic.co/guide/en/kibana/current/index.html)
- [Logstash Logback Encoder](https://github.com/logfellow/logstash-logback-encoder)
- [Spring Boot Logging](https://docs.spring.io/spring-boot/docs/current/reference/html/features.html#features.logging)

---

## üìù Notas

- Los logs en `dev` profile usan formato legible (no JSON) para facilitar debugging local
- El header `X-Trace-ID` permite correlacionar requests distribuidos
- MDC se limpia autom√°ticamente en `LoggingContextFilter.finally` para evitar memory leaks
- Logstash procesa logs en tiempo real (TCP) y desde archivos (rotaci√≥n)
- Elasticsearch indices se crean autom√°ticamente con patr√≥n `logs-pymerp-YYYY.MM.dd`

---

**Versi√≥n:** 1.0  
**√öltima actualizaci√≥n:** 7 de noviembre de 2025  
**Mantenido por:** PYMERP Development Team
